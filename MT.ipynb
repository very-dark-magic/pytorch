{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/bentrevett/pytorch-seq2seq/blob/master/4%20-%20Packed%20Padded%20Sequences%2C%20Masking%2C%20Inference%20and%20BLEU.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en\n",
    "#!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy, random, math, time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load(\"de\")\n",
    "spacy_en = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# define Field -- data processing\n",
    "SRC = Field(tokenize=\"spacy\", tokenizer_language=\"de\", init_token=\"<sos>\", \n",
    "            eos_token=\"<eos>\", lower=True, include_lengths=True)\n",
    "TRG = Field(tokenize=\"spacy\", tokenizer_language=\"en\", init_token=\"<sos>\", \n",
    "            eos_token=\"<eos>\", lower=True)\n",
    "\n",
    "# load data\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts=(\".de\", \".en\"), fields=(SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocab\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create iterators\n",
    "BATCH_SIZE = 128\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=device,\n",
    "        sort_within_batch=True, sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 128])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iterator)).src[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
       "        [  4,   4,   4,  ...,   4,   4,   4],\n",
       "        [  9,  14, 851,  ..., 120,   9, 224],\n",
       "        ...,\n",
       "        [  1,   1,   1,  ...,   1,   1,   1],\n",
       "        [  1,   1,   1,  ...,   1,   1,   1],\n",
       "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iterator)).trg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_len):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len, batch_first = False)\n",
    "        \n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "        # packed_outputs is a packed seq containing all hidden states\n",
    "        # hidden is the final non-padded element in the batch\n",
    "        \n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)      \n",
    "        #outputs = [src len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using masking, force attention layer to focus on non-padding elements\n",
    "# we apply mask after the attention has been calculated, but before it has been normalized by softmax\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(enc_hid_dim*2 + dec_hid_dim, dec_hid_dim)\n",
    "        ## nn.Linear operates on the last dim\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden = [batch_size, dec_hidden_dim]\n",
    "        # encoder_outputs = [src_len, batch_size, enc_hid_dim*2]\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        # repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))\n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        #attention= [batch size, src len]\n",
    "        attention = attention.masked_fill(mask == 0, -1e10)\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #mask = [batch size, src len] --> from soruce sentence\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs, mask)\n",
    "                \n",
    "        #a = [batch size, src len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        mask = (src!=self.src_pad_idx).permute(1, 0)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        mask = self.create_mask(src)\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7855, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 20,518,917 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src, src_len = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, src_len, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src, src_len = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, src_len, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 45s\n",
      "\tTrain Loss: 5.067 | Train PPL: 158.756\n",
      "\t Val. Loss: 4.810 |  Val. PPL: 122.714\n",
      "Epoch: 02 | Time: 0m 45s\n",
      "\tTrain Loss: 4.159 | Train PPL:  64.006\n",
      "\t Val. Loss: 4.178 |  Val. PPL:  65.227\n",
      "Epoch: 03 | Time: 0m 45s\n",
      "\tTrain Loss: 3.391 | Train PPL:  29.709\n",
      "\t Val. Loss: 3.638 |  Val. PPL:  38.008\n",
      "Epoch: 04 | Time: 0m 44s\n",
      "\tTrain Loss: 2.867 | Train PPL:  17.578\n",
      "\t Val. Loss: 3.384 |  Val. PPL:  29.492\n",
      "Epoch: 05 | Time: 0m 44s\n",
      "\tTrain Loss: 2.507 | Train PPL:  12.273\n",
      "\t Val. Loss: 3.218 |  Val. PPL:  24.970\n",
      "Epoch: 06 | Time: 0m 44s\n",
      "\tTrain Loss: 2.205 | Train PPL:   9.066\n",
      "\t Val. Loss: 3.194 |  Val. PPL:  24.376\n",
      "Epoch: 07 | Time: 0m 44s\n",
      "\tTrain Loss: 1.964 | Train PPL:   7.126\n",
      "\t Val. Loss: 3.172 |  Val. PPL:  23.861\n",
      "Epoch: 08 | Time: 0m 45s\n",
      "\tTrain Loss: 1.744 | Train PPL:   5.721\n",
      "\t Val. Loss: 3.281 |  Val. PPL:  26.613\n",
      "Epoch: 09 | Time: 0m 45s\n",
      "\tTrain Loss: 1.616 | Train PPL:   5.035\n",
      "\t Val. Loss: 3.268 |  Val. PPL:  26.246\n",
      "Epoch: 10 | Time: 0m 45s\n",
      "\tTrain Loss: 1.459 | Train PPL:   4.304\n",
      "\t Val. Loss: 3.393 |  Val. PPL:  29.756\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.150 | Test PPL:  23.331 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut3-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load(\"de\")\n",
    "        tokens = [tok.text.lower() for tok in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [tok.lower() for tok in sentence]\n",
    "        \n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "    \n",
    "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
    "    mask = model.create_mask(src_tensor)\n",
    "    \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "    \n",
    "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
    "        attentions[i] = attention\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        \n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(sentence, tranlation, attention):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                       rotation=45)\n",
    "    ax.set_yticklabels(['']+translation)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['ein', 'schwarzer', 'hund', 'und', 'ein', 'gefleckter', 'hund', 'kämpfen', '.']\n",
      "trg = ['a', 'black', 'dog', 'and', 'a', 'spotted', 'dog', 'are', 'fighting']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 12\n",
    "\n",
    "src = vars(train_data.examples[example_idx])['src']\n",
    "trg = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg = ['a', 'black', 'dog', 'and', 'a', 'spotted', 'dog', 'fighting', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU\n",
    "\n",
    "BLEU looks at the overlap in the predicted and actual target sequences in terms of their n-grams. The score is between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
    "    \n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for datum in data:\n",
    "        \n",
    "        src = vars(datum)['src']\n",
    "        trg = vars(datum)['trg']\n",
    "        \n",
    "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
    "        \n",
    "        #cut off <eos> token\n",
    "        pred_trg = pred_trg[:-1]\n",
    "        \n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    return bleu_score(pred_trgs, trgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 29.41\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n",
    "\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
